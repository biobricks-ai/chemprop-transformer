\section{Abstract}

Quantitative Structure-Activity Relationship (QSAR) models have been instrumental in predicting chemical properties, but they typically focus on modeling individual properties in isolation. This approach limits their ability to leverage comprehensive datasets and integrate information across multiple properties. Our study addresses this limitation by introducing a novel transformer-based tool that predicts sequences of property values. This approach not only enables the simultaneous prediction of multiple chemical properties but also integrates information across these properties. By leveraging both chemical structure and known properties, our model can make more accurate and holistic predictions about a chemical's characteristics. Furthermore, this capability allows us to explore counterfactual scenarios, such as "If a chemical has property X, what is the likelihood it has property Y?" These advancements open new avenues for building efficient policies in chemical testing and deepening our understanding of complex property relationships in chemistry.

We present an encoder-decoder transformer model that predicts chemical properties based on both molecular structure and known properties of a target chemical. The model tokenizes Self-Referencing Embedded Strings (SELFIES) of molecules along with sequences of their property-value pairs, using a causal mask to generate property-value sequence outputs. This approach allows the model to predict chemical properties by leveraging embeddings of property-tokens, other known properties, and chemical structures.

Trained on the extensive ChemHarmony dataset, which encompasses information on 118 million substances, our model demonstrates the ability to make more accurate predictions when provided with additional chemical information. For instance, if a chemical is known to have a low acute oral LD50, the model can use this information to inform predictions about its acute inhalation LC50.
\todo{we should use an example from our results}

Our 'property-value-transformer' model addresses key issues in the QSAR space by enabling transfer learning between chemical properties and directly modeling properties as functions of other properties. This capability allows for conditional predictions and potential counterfactual analysis, marking a significant advancement in the field of chemical property prediction.
